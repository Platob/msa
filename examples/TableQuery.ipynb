{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d820c0b2-59d9-4c9b-9c2b-9dbf575a69f1",
   "metadata": {},
   "source": [
    "## Download / Install MSSQL Express for local db\n",
    "\n",
    "Website: https://www.microsoft.com/fr-fr/sql-server/sql-server-downloads\n",
    "\n",
    "Download 2019: https://go.microsoft.com/fwlink/?linkid=866658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1a4a0-bd0c-461b-bbe8-13e641701894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from msa.odbc import PyODBC\n",
    "\n",
    "server = PyODBC(\n",
    "    uri=\"Server=localhost\\SQLEXPRESS01;Database=master;DRIVER={ODBC Driver 18 for SQL Server};\"\n",
    "        \"Trusted_Connection=yes;TrustServerCertificate=YES;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe1c28-0e2e-4572-b837-ea24fea6e1a0",
   "metadata": {},
   "source": [
    "## Init data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26a7dc-18d2-462c-ad92-7cbf94b58472",
   "metadata": {},
   "outputs": [],
   "source": [
    "with server.cursor() as c:\n",
    "    try:\n",
    "        c.execute(f\"DROP TABLE PYMSA_UNITTEST\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    c.execute(f\"\"\"CREATE TABLE PYMSA_UNITTEST (\n",
    "ID int IDENTITY PRIMARY KEY,\n",
    "int int,\n",
    "bigint bigint,\n",
    "bit bit,\n",
    "decimal decimal,\n",
    "float float,\n",
    "real real,\n",
    "date date,\n",
    "datetime datetime,\n",
    "datetime2 datetime2,\n",
    "smalldatetime smalldatetime,\n",
    "time time,\n",
    "string varchar(64) not null,\n",
    "binary varbinary(64)\n",
    ")\"\"\")\n",
    "    c.commit()\n",
    "    c.execute(f\"TRUNCATE TABLE PYMSA_UNITTEST\")\n",
    "    c.executemany(\n",
    "        \"INSERT INTO [master].[dbo].[PYMSA_UNITTEST]([int],[string]) VALUES (?,?),(?,?)\",\n",
    "        [[1, '1', 2, '2']]\n",
    "    )\n",
    "    c.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a65164-fdaf-433c-a78b-55323cbe0618",
   "metadata": {},
   "source": [
    "## Fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7d67e-c38f-483a-be8d-6e319a7ddb4e",
   "metadata": {},
   "source": [
    "### Main thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000cd366-0f5d-41cd-9afa-ea259c1e72da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with server.cursor() as c:\n",
    "    result = c.execute(f\"SELECT * from PYMSA_UNITTEST\").fetchall()\n",
    "    result = [list(row) for row in result]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ff001-003a-47d9-a6db-b894bdfbb42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with server.cursor() as c:\n",
    "    c.execute(f\"SELECT * from PYMSA_UNITTEST\")\n",
    "    result = list(c.fetch_arrow_batches(n=10)) # Iterator pyarrow.RecordBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83bcbfe-b87e-47bd-ad02-227b791baa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with server.cursor() as c:\n",
    "    c.execute(f\"SELECT * from PYMSA_UNITTEST\")\n",
    "    result = c.fetch_arrow() # all, pyarrow.Table\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c729d9-ee67-4536-9a4c-a9d9db50f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with server.cursor() as c:\n",
    "    c.execute(f\"SELECT int, string, date, float, real from PYMSA_UNITTEST\")\n",
    "    pyarrow_batch_reader = c.reader() # pyarrow.RecordBatchReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52100f14-edf8-4eb7-b71a-a72840f2bcc1",
   "metadata": {},
   "source": [
    "### Concurrent cursor execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400e01a-9a33-42cf-a555-0881d38beaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def r(x):\n",
    "    return x.fetch_arrow()\n",
    "    \n",
    "tables = list(server.map(\n",
    "    \"execute\", # getattr(cursor, method) or callable like def func(cursor, *args, **kwargs)\n",
    "    result_wrapper=r,\n",
    "    arguments=[\n",
    "        ([f\"select * from PYMSA_UNITTEST\"], {}) # (args, kwargs)\n",
    "        for _ in range(1000)\n",
    "    ],\n",
    "    concurrency=os.cpu_count() # default\n",
    "))\n",
    "len(tables), tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c693f1d-47e7-450a-8f01-d1a4a4537ff2",
   "metadata": {},
   "source": [
    "## SQLTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d1cde-4043-401a-b5bf-01e7dba5f51a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with server.connect() as connection:\n",
    "    table = connection.table(name=\"PYMSA_UNITTEST\")\n",
    "    schema_arrow = table.schema_arrow\n",
    "schema_arrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f0db97-e031-4ad3-81e6-9784ee5a8e68",
   "metadata": {},
   "source": [
    "## Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc5283-3aec-44bc-9385-911adbc9442c",
   "metadata": {},
   "source": [
    "### Classic INSERT INTO VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbdeb8d-7c44-44fb-8cb8-47ab38706f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "with server.connect(timeout=30) as connection: # timeout in seconds   \n",
    "    with connection.cursor() as c:\n",
    "        table = c.table(name=\"PYMSA_UNITTEST\")\n",
    "\n",
    "        c.insert_pylist(\n",
    "            table=table,\n",
    "            rows=[[datetime.datetime.now(), datetime.datetime.now(), 1, b\"bytes\"]],\n",
    "            columns=[\"string\", \"datetime2\", \"int\", \"binary\"],\n",
    "            commit=True,\n",
    "            commit_size=10, # number of rows to commit, max = 1000, default = 1, set > 1 IT'S FASTER ! but random order\n",
    "        )\n",
    "        c.execute(f\"SELECT * from PYMSA_UNITTEST\")\n",
    "    \n",
    "        batches = list(c.fetch_arrow_batches(n=10))\n",
    "    \n",
    "    table.truncate()\n",
    "    with table.cursor as c:\n",
    "        c.set_identity_insert(table, True)\n",
    "        c.insert_arrow(\n",
    "            table=table,\n",
    "            data=batches, # pyarrow.RecordBatch, pyarrow.RecordBatchReader, pyarrow.Table or Iterable[RecordBatch]\n",
    "            cast=True,\n",
    "            safe=True,\n",
    "            commit=True,\n",
    "            delayed_check_constraints=True, # delay constraints check at the end\n",
    "            check_constraints=False # check table constraints on insert\n",
    "        )\n",
    "    \n",
    "    result = connection.cursor().execute(\"SELECT * from PYMSA_UNITTEST\").fetchall()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d6af6-1d8b-4b18-91ce-188eb9b69e9d",
   "metadata": {},
   "source": [
    "### Bulk Insert with CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fb04fd-c9b8-4be8-8df9-c80e25417175",
   "metadata": {},
   "outputs": [],
   "source": [
    "with server.connect() as connection:\n",
    "    table = connection.table(name=\"PYMSA_UNITTEST\")\n",
    "    data = connection.cursor().execute(\"SELECT * from PYMSA_UNITTEST\").fetch_arrow()\n",
    "    \n",
    "    table.insert_arrow(data, commit=True, bulk=True)\n",
    "    table.bulk_insert_arrow(data, commit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5fda6c-248b-4adc-b90f-22a0d8bc3242",
   "metadata": {},
   "source": [
    "### Insert parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee259d1c-9022-4ee7-b73d-9fecd5d4cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow, io\n",
    "import pyarrow.parquet as p\n",
    "\n",
    "def gen_data(n: int):\n",
    "    return pyarrow.Table.from_arrays([\n",
    "        pyarrow.array(['test%s' % i for i in range(n)]),\n",
    "        pyarrow.array(['dropped' for i in range(n)])\n",
    "    ], schema=pyarrow.schema([\n",
    "        pyarrow.field(\"string\", pyarrow.string(), nullable=False),\n",
    "        pyarrow.field(\"dropped\", pyarrow.string(), nullable=False)\n",
    "    ]))\n",
    "\n",
    "buf = io.BytesIO()\n",
    "p.write_table(gen_data(10), buf)\n",
    "buf.seek(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661784e-cffb-4e36-98b0-802fbb9c36a7",
   "metadata": {},
   "source": [
    "### Insert parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b653d9e-e788-4611-8990-512f4d6c02f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarrow.fs import LocalFileSystem\n",
    "\n",
    "with server.connect() as connection:\n",
    "    # SQLTable methods build default cursor with connection.cursor()\n",
    "    table = connection.table(name=\"PYMSA_UNITTEST\")\n",
    "    \n",
    "    table.truncate()\n",
    "    \n",
    "    table.insert_parquet_file(\n",
    "        buf, # or filesystem path, file-object, Native file like pyarrow.parquet.write_table\n",
    "        batch_size=65536, # default = 65536\n",
    "        commit=True,\n",
    "        bulk=False, # CSV bulk insert\n",
    "        filesystem=LocalFileSystem() # pyarrow.fs.FileSystem, default = LocalFileSystem()\n",
    "    )\n",
    "    # or with cursor.insert_parquet_file(table, buf, ...)\n",
    "    \n",
    "    result = connection.cursor().execute(\"SELECT * from PYMSA_UNITTEST\").fetch_arrow()\n",
    "result.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e1651-9a76-40c0-91d2-d1fd40288e42",
   "metadata": {},
   "source": [
    "### Insert parquet dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a7ce7b-4e59-4f7d-9165-794f7bfff6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as p\n",
    "import os\n",
    "\n",
    "base_dir = \"parquets\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "for i in range(1, 3):\n",
    "    folder = \"%s/partition=%s\" % (base_dir, i)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    p.write_table(gen_data(i), \"%s/part%s.parquet\" % (base_dir, i))\n",
    "    p.write_table(gen_data(i), \"%s/part%s.parquet\" % (folder, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9d40a-f67f-4a75-8a89-835375434451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.compute as pc\n",
    "\n",
    "with server.cursor() as cursor:\n",
    "    table = cursor.table(\"PYMSA_UNITTEST\")\n",
    "    table.truncate()\n",
    "    \n",
    "    def a(batch):\n",
    "        filtered_batch = batch.filter(pc.equal(batch['string'], 'test0'))\n",
    "        print(filtered_batch.num_rows)\n",
    "        return filtered_batch\n",
    "\n",
    "    cursor.insert_parquet_dir(\n",
    "        table,\n",
    "        base_dir, # or filesystem dir path only\n",
    "        batch_size=65536, # default\n",
    "        commit=True,\n",
    "        bulk=False, # CSV bulk insert\n",
    "        # see https://arrow.apache.org/docs/python/generated/pyarrow.parquet.read_table.html\n",
    "        file_filters=[('string', 'in', ['test0', 'test1'])], # filter on file read\n",
    "        batch_apply=a, # apply on each batch\n",
    "        filesystem=LocalFileSystem() # pyarrow.fs.FileSystem, default = LocalFileSystem()\n",
    "    )\n",
    "    # or with cursor.insert_parquet_dir(table, \"path/to/dir\", ...)\n",
    "\n",
    "    result = cursor.execute(\"SELECT * from PYMSA_UNITTEST\").fetch_arrow().to_pandas()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df254c-9752-4dae-9b18-51197267a9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21171c21-d9f6-40e1-a5b8-de5c153497d7",
   "metadata": {},
   "source": [
    "## SQLView: inherit SQLTable\n",
    "So you can insert in it too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a46da-a58c-463d-b67e-0c8d901fa23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with server.connect() as connection:\n",
    "    connection.cursor().execute(\"CREATE VIEW vPYMSA_UNITTEST AS SELECT string, int from PYMSA_UNITTEST\")\n",
    "    \n",
    "    table = connection.view(\"vPYMSA_UNITTEST\")\n",
    "    table.schema_arrow # persist\n",
    "table.schema_arrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f690c9-165f-4c00-b2e6-2654f5abd0c9",
   "metadata": {},
   "source": [
    "## SQLIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320dbf03-9a64-4590-9369-02c5488ac279",
   "metadata": {},
   "outputs": [],
   "source": [
    "with server.cursor() as c:\n",
    "    table = c.table(\"PYMSA_UNITTEST\")\n",
    "    print(c.create_table_index.__doc__)\n",
    "    c.create_table_index(\n",
    "        table=table,\n",
    "        type=\"\",\n",
    "        columns=[\"string\", \"int\"]\n",
    "    )\n",
    "    c.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d554e-acec-47a7-864f-217fd42aade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045d4f1-5312-4539-b668-6797d905172d",
   "metadata": {},
   "source": [
    "### Insert with indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62493f6-57e9-4c1b-9a57-dad0ce3903d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with server.cursor() as c:\n",
    "    table.truncate()\n",
    "    c.set_identity_insert(table, True)\n",
    "    c.disable_table_all_indexes(table, except_primary_key=True)\n",
    "    c.insert_arrow(\n",
    "        table=table,\n",
    "        data=batches, # pyarrow.RecordBatch, pyarrow.RecordBatchReader, pyarrow.Table or Iterable[RecordBatch]\n",
    "        cast=True,\n",
    "        safe=True,\n",
    "        commit=True\n",
    "    )\n",
    "    c.rebuild_table_all_indexes(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6205f-73e0-4c37-960a-7ef622e9e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.cursor.execute(\"SELECT * from PYMSA_UNITTEST\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb9fb4-3506-44d2-ab87-5ee13ddffe19",
   "metadata": {},
   "source": [
    "## Drop SQLTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4790e4-6548-4c75-a7bb-e0d8e95137ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with server.connect() as connection:\n",
    "    connection.table(name=\"PYMSA_UNITTEST\").drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b75b042-b07d-4a90-81c0-e757c0ffba7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
